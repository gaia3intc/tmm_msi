\documentclass[a4paper]{article}
\title{A Quick Introduction to TMM}
\author{Tatsuro Tanioka}
\date{\today}

\usepackage[margin=1in]{geometry}
\usepackage{xcolor}
\usepackage{listings}
\lstdefinestyle{DOS}
{
    backgroundcolor=\color{black},
    basicstyle=\scriptsize\color{white}\ttfamily
}
\usepackage{natbib}
\usepackage{mathtools,amsthm}    % some advanced mathematics notation
\usepackage{graphicx}            % easy inclusion and manipulation of images
\graphicspath{ {./Figures_tutorial/} }
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{float}
\usepackage{microtype}           % just for fun: really hone in with the typography
\usepackage{booktabs}            % nice looking tables that present the content first and foremost
\usepackage{multicol}            % multiple columns in a local context
\usepackage[hidelinks]{hyperref} % clickable references in the output, but hide them visually
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{newtxtext,newtxmath}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=black,
%    pdftitle={Sharelatex Example},
%    bookmarks=true,
%    pdfpagemode=FullScreen,
    }
    
\urlstyle{same}

\def\noin{\noindent }
\def\CO{$\mathrm{CO_{2}}$ }
%%%%%%%%%%%%%----------------------------------------------------------
\begin{document}
\maketitle

\begin{abstract}
This document goes through how to use the Transport Matrix Model (TMM) using computational resources at the University of Minnesota's Minnesota Supercomputing Institution (MSI). All the source codes and documents (including this tutorial) that Tanioka made to TMM is available at my github website \url{(https://github.com/tanio003/tmm/tree/TT_Release)}.
\end{abstract}

\tableofcontents

\section{Setting up}

\subsection{Flow Chart}
Before you do anything, read ``README.txt'' by Samar Khatiwala at the following website: \\ \url{https://github.com/samarkhatiwala/tmm}. I will go over each of these steps specifically aimed at audiences using the computational cluster \emph{Mesabi}.
\begin{enumerate}
\item Installing and configuring PETSc
\item Downloading all the scripts and transport matrices into your own local directory
\item Compiling the model (we use the BGC model \verb/MOPS2/ for this example)
\item Running the model
\item Processing the model outputs
\item Displaying the model outputs
\end{enumerate}

\subsection{Steps}

\subsubsection{Step 0: Logging into MSI and Mesabi}
\noin Open the terminal (assuming that you have a MAC or Linux environment) on your computer and log in to MSI with your x500 account:
\begin{lstlisting}[style=DOS]
 $ ssh -Yt youremail@umn.edu
\end{lstlisting}

\noin Log in to Mesabi: 
\begin{lstlisting}[style=DOS]
 $ ssh -X mesabi
\end{lstlisting}

\noin Make a new directory called TMM2 in your home directory and enter into this directory. Everything related to TMM will go into this directory.
\begin{lstlisting}[style=DOS]
 $ mkdir TMM2
 $ cd TMM2
\end{lstlisting}

\subsubsection{Step 1: Installing and configuring PETSc}

\noin Download the latest version of PETSc and save it in your TMM2 directory and unzip this package. If opened properly, you should see the new directory petsc-3.13.5. 
\begin{lstlisting}[style=DOS]
 $ wget http://ftp.mcs.anl.gov/pub/petsc/release-snapshots/petsc-lite-3.13.5.tar.gz
 $ tar -xvf petsc-lite-3.13.5.tar.gz
 $ ls
 petsc-3.13.5
\end{lstlisting}

\noin Import the required modules: (1) impi, (2) impi/intel, and (3) cmake. Also make sure that you are using python 3, not python 2 (= default for MSI). 
\begin{lstlisting}[style=DOS]
 $ module purge 
 $ module load intel
 $ module load impi/intel
 $ module load cmake
 $ module load python3
 $ module list
Currently Loaded Modulefiles:
 1) intel/2018.release(default)   4) cmake/3.10.2(default)
 2) intel/2018/release            5) python3/3.7.1_anaconda
 3) impi/intel(default)
\end{lstlisting}

\noin Set up \verb/$PETSC_DIR/ to your petsc-3.13.5 directory. For your future uses, I would advise you to set \verb|$PETSC_DIR| in your \verb|.bashrc| as well. 
\begin{lstlisting}[style=DOS]
 $ export PETSC_DIR=$HOME/TMM2/petsc-3.13.5
 $ echo $PETSC_DIR 
 /.../TMM2/petsc-3.13.5
\end{lstlisting}

\noin Configure PETSc. Although this part is quite tricky you can copy and use my config file \\ ``\verb/reconfigure-arch-linux-c-opt.py/''. If the config file does not work properly, let me know and I can show you a way to compile without using this .py file. 
\begin{lstlisting}[style=DOS]
 $ cd petsc-3.13.5
 $ cp ~/../tanio003/TMM2/petsc-3.13.5/config/reconfigure-arch-linux-c-opt.py config/
 $ config/reconfigure-arch-linux-c-opt.py
\end{lstlisting}

\noin Don't worry about some warning signs. It takes few minutes to compile. If it's compiled properly you should see the notice ``Conifgure stage complete.'' Then build PETSc library:
\begin{lstlisting}[style=DOS]
 $ make all
\end{lstlisting}
Building process takes about 15-30 minutes. If you're very lucky it will go through in a single shot. But in most cases, it fails during the middle of the process. Don't worry if it fails the first time. Simply type ``\verb/$ make all/'' again and hopefully it will finish building from where it left off. If built properly, you should see the message ``Now to check if the libraries are working do:...''. Then type,
\begin{lstlisting}[style=DOS]
 $ make check
 ...
Completed test examples
\end{lstlisting}
If you get this far, you've managed to build the PETSc successfully and you're ready to go to the next step. If it failed, read the error messages, debug, and try again. \textbf{Building PETSc is harder than it looks} so you need to be patient. 

As more of a technical note, the procedure above uses the Intel compilers and Intel MPI library. By loading the cmake, the PETSc build system can learn more about the host machine. In addition to taking advantage of compiler optimizations and vectorization, the procedure above builds PETSc against the Intel Math Kernel Library (MKL) for BLAS, LAPACK and ScaLAPACK which gives a performance gain over the reference implementations. For the FORTRAN compiler, we specifically need to use \verb/mpiifort/, and not \verb/mpif90/ (the default compiler), because TMM codes are written in both F77 and F90. Also, since we don't require C++ for TMM we put the flag in the config file, \verb/--with-cxx=0/. The reason we need to use MPI compilers, not regular gcc compilers, is because we want to run PETSc in a parallel mode (i.e., by using the command \verb/mpiexec/ in the runscript). For more details about building PETSc please check out \url{https://www.mcs.anl.gov/petsc/documentation/installation.html}. 

\subsubsection{Step 2: Downloading all the scripts and transport matrices}
\begin{enumerate}
\item First download Matlab scripts from \\ 
\url{http://kelvin.earth.ox.ac.uk/spk/Research/TMM/tmm_matlab_code.tar.gz} and put into the first level of your TMM2 folder Path. You could also get my copy.
\begin{lstlisting}[style=DOS]
 $ cp -r ~/../tanio003/TMM2/tmm_matlab_code $HOME/TMM2/
\end{lstlisting}
\item Download transport matrices and related data for the model of your choice: \\ \url{http://kelvin.earth.ox.ac.uk/spk/Research/TMM/TransportMatrixConfigs/} and put into he first level of your TMM2 folder Path. You can download all 6 configurations but I warn you that \verb|MITgcm_ECCO_v4| and \verb|UVicKielIncrIsopycDiffTransient| take a very long time. For the ones that I have you could also grab my copy (e.g., to copy \verb|MITgcm_ECCO|):
\begin{lstlisting}[style=DOS]
 $ cp -r ~/../tanio003/TMM2/MITgcm_ECCO $HOME/TMM2/
\end{lstlisting}

\noin Alternatively, you can get download these TMM files from the web directly (e.g., to download \verb|MITgcm_ECCO|):
\begin{lstlisting}[style=DOS]
 $ wget kelvin.earth.ox.ac.uk/spk/Research/TMM/TransportMatrixConfigs/MITgcm_ECCO.tar
 $ tar -xvf MITgcm_ECCO.tar
\end{lstlisting}

\item Download miscellaneous data called OceanCarbon from \\ 
\url{http://kelvin.earth.ox.ac.uk/spk/Research/TMM/MiscData/}. You can get my copy by:
\begin{lstlisting}[style=DOS]
 $ cp -r ~/../tanio003/TMM2/OceanCarbon $HOME/TMM2/
\end{lstlisting}
\item Download source codes for TMM and models:
\begin{lstlisting}[style=DOS]
 $ git clone https://github.com/tanio003/tmm
\end{lstlisting}
 This directory (\verb|/TMM2/tmm|) contains the source codes from Khatiwala's master branch (``\verb|master|'') and my public release branch (``\verb|TT_Release|''). For our exercise, we will be using some of my new codes so you need to switch from the master branch to my branch in the newly created tmm directory:
\begin{lstlisting}[style=DOS]
 $ cd tmm
 (master) $ ls
 driver  HOWTO.txt  LICENSE.txt  models  README.txt
 (master) $ git checkout TT_Release
 (TT_Release) $ ls
 driver  HOWTO.txt  LICENSE.txt  models  README.txt  Tutorial_MSI
\end{lstlisting}
Notice that in the branch \verb|TT_Release|, there is a new directory \verb|Tutorial_MSI|, which was not present in the master branch. 

(Optional) If you want to make start making your own changes to the source codes, I would suggest making a new branch in your local computer (e.g.., \verb|yournewrepo|), and leave \verb|master| and \verb|TT_Release| untouched.
\begin{lstlisting}[style=DOS]
 (TT_Release) $ git checkout -b yournewrepo
 (yournewrepo) $ git branch --show-current
 yournewrepo
\end{lstlisting}
\item Set the environment variable TMMROOT to point to the top level of the TMM directory.
\begin{lstlisting}[style=DOS]
 (TT_Release) $ export TMMROOT=$HOME/TMM2/tmm
 (TT_Release) $ echo $TMMROOT
 /home/.../TMM2/tmm
\end{lstlisting}

For your future convenience, I would advise you to set \verb|$TMMROOT| in your \verb|.bashrc| as well so you don't need to set the variable every time you log in to MSI. 

\item To synchronize your \verb|tmm| folder with the remote repository (e.g., syncing \verb|TT_Release| with my updates), use the git pull command your terminal. I suggest you do this regularly to keep your files up to date.
\begin{lstlisting}[style=DOS]
 $ cd $TMMROOT
 $ git checkout TT_Release
 $ git pull origin TT_Release
\end{lstlisting}

\end{enumerate}

\subsubsection{Step 3: Compiling the model}
\noin Here, let's try compiling the biogeochemical MOPS. If you want to learn about the basic architecture of MOPS, read the model description paper by \citet{Kriest15} at \url{https://gmd.copernicus.org/articles/8/2929/2015/}. 

\begin{enumerate}
\item For each model there are model-specific source codes \\ (\verb|$TMMROOT/models/current/mops2/src/|); Matlab scripts \\ (\verb|$TMMROOT/models/current/mops2/matlab/|) to generate input data and read model output; and run scripts and other runtime data such as namelists in \\ 
\verb|$TMMROOT/models/current/mops2/runscripts/|. 

First, we create a new run directory. I make a new base directory called ``\verb|Runs|'' and in that directory, I make subdirectories for specific experiments. I call it \verb|Runs/MOPS/Test_spinup| and copy here all the files needed.

\begin{lstlisting}[style=DOS]
 $ cd ~/TMM2
 $ mkdir -p Runs/MOPS/TMM_spinup
 $ cd Runs/MOPS/TMM_spinup
 $ cp -p $TMMROOT/models/current/mops2.0/src/Makefile .
 $ cp -p -R $TMMROOT/models/current/mops2.0/matlab/* .
 $ cp -p $TMMROOT/models/current/mops2.0/runscripts/* .
\end{lstlisting}

\item Compile mops. Make sure that all the modules are loaded and \verb|$PETSC_DIR| is set correctly before you compile mops.
\begin{lstlisting}[style=DOS]
 $ module load intel
 $ module load impi/intel
 $ module load cmake
 $ make clean all
 $ make mops
\end{lstlisting}

\noin If compiled properly, you'd find a new executable ``mops'' created along with a bunch of objective .o files. 
\lstset{emph={mops,runscript_msi,Makefile}, emphstyle=\color{green}}
\begin{lstlisting}[style=DOS]
 $ ls
 BGC_INI.o                           n7fluxes28.m
 BGC_MODEL.o                         n7physics.m
 CAR_CHEM.o                          n7tracers28.m
 CAR_INI.o                           n7tracersavg28.m
 external_forcing_mops_biogeochem.o  perry1996-runoff-noarctic_noname.txt
 insolation.o                        perry1996-runoff_noname.txt
 load_output.m                       petsc_matvec_utils.o
 load_output_time_avg.m              petsc_signal_utils.o
 load_pco2.m                         process_output.m
 Makefile                            runscript
 make_input_files_for_mops_model.m   runscript_msi
 make_rivers.m                       tmm_external_bc.o
 misfit_mops_biogeochem.o            tmm_forcing_utils.o
 mops                                tmm_forward_step.o
 mops_biogeochem_copy_data.o         tmm_main.o
 mops_biogeochem_diagnostics.o       tmm_monitor.o
 mops_biogeochem_ini.o               tmm_profile_utils.o
 mops_biogeochem_misfit.o            tmm_timer.o
 mops_biogeochem_model.o             tmm_write.o
 mops_biogeochem_set_params.o
\end{lstlisting}
\lstset{emph={}, emphstyle=\color{green}}

\item Edit the file \ \verb/make_input_files_for_mops_model.m/. First thing to do is to make sure that variable \verb/base_path/ point to the right directory for the TMM configuration.
\lstset{language=matlab} 
\begin{lstlisting}[frame=single,basicstyle=\scriptsize,commentstyle=\color{blue}]
 % make_input_files_for_mops_model.m
 
 % Set toplevel path to GCMs configuration
 % base_path='/data2/spk/TransportMatrixConfigs/MITgcm_2.8deg';
 % base_path='/data2/spk/TransportMatrixConfigs/MITgcm_ECCO';
 % base_path='/data2/spk/TransportMatrixConfigs/MITgcm_ECCO_v4';
 base_path='~/TMM2/MITgcm_2.8deg';
 
 addpath(genpath('~/TMM2/tmm_matlab_code'));% add tmm_matlab_code to the search path
 oceanCarbonBasePath='~/TMM2/OceanCarbon';  % add OceanCarbon to the search path
 atmosDataPath=fullfile(oceanCarbonBasePath,'AtmosphericCarbonData');
\end{lstlisting}
\noin In the same matlab file, there are different switches (0 = no and 1 = yes). For this spin-up exercise, we \textbf{couple MOPS to a simple OCMIP-like carbon model} and \textbf{fix atmospheric $\mathrm{pCO_{2}}$ at 280 ppm}. So set the switches as following:
\begin{lstlisting}[frame=single,basicstyle=\scriptsize,commentstyle=\color{blue}]
 % make_input_files_for_mops_model.m
 ...
 periodicForcing=1 
 periodicMatrix=1
 
 dt=43200; % time step to use (43200s for ECCO and MIT2.8; 28800s for any other TMMs)
 
 rearrangeProfiles=1
 bigMat=0
 writeFiles=1
 writeTMs=1
 useCoarseGrainedMatrix=0
 writePCFiles=0
 
 READ_SWRAD=0                    % Read short-wave radiation?
 useCarbon=1                     % Use simple inorganic carbon model?
 useAtmModel=0                   % Use prognostic 1-box atmosphere?
 pCO2atm_ini=280.0               % Initial pco2?
 useTimeVaryingPrescribedCO2=0   % Use prescribed pco2 pathway?
 useVirtualFlux=1                % Use DIC and Alk to calculate E-P?
 empScaleFactor=1.0              % Scaling factor for E-P (default = 1)
 %-----------------------------------
 % Modified by Tatsuro Tanioka 200907 to allow for Atmospheric CO2 option
 % For a prescribed pCO2 run, useTimeVaryingPrescribedCO2=1 and choose a scenario
 
 % Available options: 'historical', 'RCP3PD', 'RCP45', 'RCP6' and 'RCP85'
 co2Scenario='RCP85';
 %-----------------------------------
\end{lstlisting}
\noin Then open MATLAB and run \verb/make_input_files_for_mops_model.m/
\begin{lstlisting}[style=DOS]
 $ module load matlab
 $ matlab -nodesktop
                                    < M A T L A B (R) >
                          Copyright 1984-2019 The MathWorks, Inc.
                     R2019a Update 5 (9.6.0.1174912) 64-bit (glnxa64)
                                      July 31, 2019
To get started, type doc.
For product information, visit www.mathworks.com.

>> make_input_files_for_mops_model
\end{lstlisting}
\noin This creates a bunch of periodic forcing files (\verb|xxx_01, xxx_02,...|), initial tracer concentrations (\verb|po4ini.petsc, no3ini.petsc,...|), and binary files (.bin and .petsc) related to model geometry and forcing.
\end{enumerate}

\subsubsection{Step 4: Running the model}
\noin MSI systems use job queues to efficiently and fairly manage when computations are executed. The queuing system at MSI is called PBS (Portable Batch System) and to submit a job to a PBS queue users create PBS job scripts. PBS script contains information on the resources requested for calculation, as well as the commands for executing the calculation. 

Below is the custom PBS script for submitting a new job to run MOPS2 using Mesabi. It's called \verb|runscript_msi| and should be in the current directory already. Here is the first 11 lines:

\lstset{language=sh} 
\begin{lstlisting}[frame=single,basicstyle=\scriptsize]
 1  #!/bin/bash -l
 2  #PBS -l walltime=06:00:00,nodes=1:ppn=24,pmem=2580mb
 3  #PBS -m abe
 4  #PBS -j oe
 5  #PBS -M tatsurobkkuk@gmail.com
 6
 7  cd $PBS_O_WORKDIR
 8
 9  module load intel
 10 module load impi/intel
 11 module load cmake
 \end{lstlisting}

\noin The first line defines which type of shell the script will be read. Here we will use the \verb|bash|. The second line contains the PBS resource request. The current job will require about 6 hours, 1 node each with 24 processor cores (ppn), and 2580 megabytes of memory per core (pmem). 

The two lines containing \verb|#PBS -m abe|, and \verb|#PBS -M tatsurobkkuk@gmail.com|. are both commands having to do with sending message emails to the user.  The first of these lines instructs the PBS system to send a message email when the job aborts, begins, or ends. The second command specifies the email address to be used.  Using the message emails is recommended because the reason for a job failure can often be determined using information in the emails. The seventh line sets the directory at which commands are executed and the lines 8-11 loads the necessary software modules. 

The follwing lines (14$\sim$) contain the commands to execute and start a specific program. Different flags need to be change accordingly depending on the nature of experiments. For more information on different options available, read ``HOWTO.txt'' by S. Khatiwala located in \verb|$TMMROOT|. 
\begin{lstlisting}[frame=single,basicstyle=\scriptsize,commentstyle=\color{blue}]
 # 360 days per year with a time step of 2 steps per day:
 14 mpiexec -np 24 -hostfile $PBS_NODEFILE ./mops \   # number of cores, models
 15   -numtracers 9 \   # number of tracers (i.e. state variables)
 16   -i po4ini.petsc,dopini.petsc,oxyini.petsc,phyini.petsc,zooini.petsc,detini.petsc,
 no3ini.petsc,dicini.petsc,alkini.petsc \ # files for initialization of BGC state variables
 17   -me Ae \   # the name of the explicit transport matrix
 18   -mi Ai \   # the name of the implicit transport matrix
 19   -t0 0.0 -iter0 0 \ # starting time[years] starting time[timesteps]: for initial run
 20   -deltat_clock 0.0013888888888889 \  # ocean timestep length[years]: 2 timesteps/day
 21   -max_steps 2160000 \   # total number of timesteps to be evaluated (here 3000 yrs)
 22   -write_time_steps 72000 \ # output frequency(in timesteps, here every 100 yrs)
 23   -o po4out.petsc,dopout.petsc,oxyout.petsc,phyout.petsc,zooout.petsc,detout.petsc,
 no3out.petsc,dicout.petsc,alkout.petsc \ # files for output of 9 BGC state variables
 24   -external_forcing \ # calculate BGC explicitly
 25   -use_profiles \
 26   -nzeuph 2 \   # number of layers in euphotic zone (2 for MIT2.8, 6 for ECCO)
 27   -biogeochem_deltat 43200.0 -days_per_year 360.0 \ # ocean timestep[seconds]
 28   -burial_sum_steps 720 \   # sum burial over a period of 720 timesteps = 1 yr
 29   -pco2atm 280.0 \   # use fixed pCO2 of 280 ppm
 30   -use_virtual_flux \ # use the global surface mean DIC and Alk to calculate E-P
 31   -periodic_matrix \  # use of periodic transport matrix
 32   -matrix_cycle_period 1.0 -matrix_num_per_period 12 \ # the unit of time is year and 
 # circulation has a periodicity of 1 year; monthly mean tranport matrix (12 TMs/year)
 33   -periodic_biogeochem_forcing \  # periodic biogeochemical forcing
 34   -periodic_biogeochem_cycle_period 1.0 -periodic_biogeochem_num_per_period 12 \
 35   -num_biogeochem_steps_per_ocean_step 8 \ # the number of BGC timestep per ocean step
 36   -separate_biogeochem_time_stepping \  # timestep BGC model separately from ocean step
 37   -time_avg -avg_start_time_step 2159281 -avg_time_steps 60 \ 
 # initial timestep for avg concentrations (for final year); avg over 60 timestep = 1 month
 38   -avg_files po4avg.petsc,dopavg.petsc,oxyavg.petsc,phyavg.petsc,zooavg.petsc,
 detavg.petsc,no3avg.petsc,dicavg.petsc,alkavg.petsc \   # avg file names
 39   -calc_diagnostics -diag_start_time_step 2159281 -diag_time_steps 60 \
 # initial timestep for diagnostic fluxes (for final year); avg over 60 timesteps = 1 month
 40   -diag_files fbgc1.petsc,fbgc2.petsc,fbgc3.petsc,fbgc4.petsc,fbgc5.petsc,fbgc6.petsc,
 fbgc7.petsc \ # diagnsotic flux files names
 41     > log   # outputting to logfile
\end{lstlisting}

\noin Currently BGC model writes the following 7 diagnostics into the different files:
\begin{enumerate}
\item \verb|fbgc1.petsc|: primary production in each box [mmol P/m3/oceantimestep]
\item \verb|fbgc2.petsc|: zooplankton grazing in each box [mmol P/m3/oceantimestep]
\item \verb|fbgc3.petsc|: detritus sedimentation through upper boundary of \\ each box [mmol P/m2/oceantimestep]
\item \verb|fbgc4.petsc|: remineralization of detrius and DOP in each box [mmol P/m3/oceantimestep]
\item \verb|fbgc5.petsc|: river runoff [mmol P/m3/oceantimestep]
\item \verb|fbgc6.petsc|: nitrogen fixation [mmol N/m3/oceantimestep]
\item \verb|fbgc7.petsc|: denitrification [mmol P/m3/oceantimestep]
\end{enumerate}

\noin To submit the job to the queue, type on the command line:
\begin{lstlisting}[style=DOS]
 $ chmod u+x runscript_msi
 $ qsub runscript_msi
\end{lstlisting}

\noin To check your job status at MSI, type:
\begin{lstlisting}[style=DOS]
 $ showq -u yourusername
\end{lstlisting}

\subsubsection{Step 5: Processing the model outputs}

\noin When the run is completed, you should receive an email from MSI (if you set it so in the runscript). You should also check you log file and the bottom of the log file should say ``Wall clock time xxx seconds''. As the output files are binary and cannot be opened on its own, we have to convert from the binary format into either netcdf (.nc) or Matlab (.mat) files using Matlab scripts.

\vspace{5mm}
\noin (Option 1, recommmended): To convert to \textbf{.nc} files you are going to use the following 5 scripts:
\begin{enumerate}
\item \verb|n7tracers28.m|: This file converts each tracer snapshot .petsc file (e.g., po4put.petsc) into a single .nc file. The MATLAB syntax is:
\begin{lstlisting}[style=DOS]
 >> n7tracers28('filename1.nc')
\end{lstlisting}
Make sure to set the basepath correctly and useCarbon=1 (when carbon model is used) and make sure that there is no .nc file with the same name already in the directory.

\item\verb|n7tracersavg28.m|: This file converts each tracer time-averaged .petsc file (e.g., po4avg.petsc) into a single .nc file. The MATLAB syntax is:
\begin{lstlisting}[style=DOS]
 >> n7tracersavg28('filename2.nc')
\end{lstlisting}
Make sure to set the basepath correctly and useCarbon=1 (when carbon model is used) and make sure that there is no .nc file with the same name already in the directory.

\item\verb|n7fluxes28.m|: This file converts each diagnostic flux .petsc file (e.g., fbgc1.petsc) into a single .nc file. The MATLAB syntax is:
\begin{lstlisting}[style=DOS]
 >> n7fluxes28('filename3.nc')
\end{lstlisting}
Make sure to set the basepath correctly and make sure that there is no .nc file with the same name already in the directory.

\item\verb|n7physics.m|: This file makes single .c files with monthly mean temperature and salinity. The MATLAB syntax is:
\begin{lstlisting}[style=DOS]
 >> n7physics('filename4.nc')
\end{lstlisting}
Make sure to set the basepath correctly and make sure that there is no .nc file with the same name already in the directory.

\item\verb|load_pco2.m|: This file makes a global mean atmospheric $\mathrm{pCO_{2}}$ file (``pco2.nc'') and surface $\mathrm{CO_{2}}$ air-sea flux file (``co2airseaflux.nc''). $\mathrm{CO_{2}}$ is in ppm and $\mathrm{CO_{2}}$ air-sea flux is in [mmol C/m2/timestep] (positive flux means $\mathrm{CO_{2}}$ is going into the sea from air). The MATLAB syntax is 
\begin{lstlisting}[style=DOS]
 >> load_pco2
\end{lstlisting}
Make sure to set the basepath and the $\mathrm{CO_{2}}$ run options correctly.

\item\verb|process_output.m| (optinal): To run all 5 scripts at once, edit and use this file. The MATLAB syntax is 
\begin{lstlisting}[style=DOS]
 >> process_output
\end{lstlisting}

\end{enumerate}

\noin (Option 2): To convert to \textbf{.mat} files you are going to run 2 scripts:
\begin{enumerate}

\item \verb|load_output.m|: This file converts each tracer snapshot .petsc file (e.g., po4put.petsc) to .mat file. Make sure to edit the \verb|base_path| and add \verb|tmm_matlab_code| to search path in lines 2 and 3.
\item \verb|load_output_time_avg.m|: This file converts each tracer average concentration .petsc file (e.g., po4avg.petsc) to .mat file. Make sure to edit the \verb|base_path| and search path correctly.
\item Unfortunately I don't have scripts for creating .mat diagnostic flux files, physics files, and $\mathrm{CO_{2}}$ files. But this should not be too hard to do and all you have to do is to modify other .m files.

\end{enumerate}

\subsubsection{Step 6: Displaying the model outputs}
\noin (Option 1): To view .nc files, I recommend the software \emph{Ferret} developed by NOAA. It is already installed in MSI, and to launch Ferret, type on the command line:
\begin{lstlisting}[style=DOS]
 $ ls *.nc
 filename1.nc filename2.nc filename3.nc filename4.nc co2airseaflux.nc pco2.nc
 $ module load ferret
 $ ferret
 	NOAA/PMEL TMAP
 	FERRET v6.82
 	Linux 2.6.32-279.1.1.el6.x86_64 64-bit - 08/03/12
 	14-Sep-20 14:49

yes? load filename1.nc
yes? sho d
     currently SET data sets:
    1> ./filename1.nc  (default)
 name     title                             I         J         K         L
 PO4                                       1:128     1:64      1:15      1:31
 DOP                                       1:128     1:64      1:15      1:31
 OXYGEN                                    1:128     1:64      1:15      1:31
 PHYTO                                     1:128     1:64      1:15      1:31
 ZOO                                       1:128     1:64      1:15      1:31
 DET                                       1:128     1:64      1:15      1:31
 NO3                                       1:128     1:64      1:15      1:31
 DIC                                       1:128     1:64      1:15      1:31
 ALK                                       1:128     1:64      1:15      1:31
\end{lstlisting}
I won't go into too much detail here but to learn more about Ferret, visit NOAA's website and take a tutorial at \url{https://ferret.pmel.noaa.gov/Ferret/documentation/ferret-tutorials}. You can make all kinds of graphs and figures with Ferret.

\vspace{5mm}
\noin (Option 2): If you want to visualize .mat files, I recommend the MATLAB package \verb|m_map|. Again, I would not go into much detail here but if you want to learn about it, download the package and take the tutorial from the developer's website: \url{https://www.eoas.ubc.ca/~rich/map.html}. Compared to Ferret, you have more freedom for customizing graphs but the downside is that you are going to have to write much longer codes.

\section{Case Studies}
\subsection{Study 1: Postindustrial $\mathrm{CO_{2}}$ uptake with MOPS+MIT2.8}
\noin In the first case study, we will simulate postindustrial $\mathrm{CO_{2}}$ uptake using MOPS and MITgcm2.8 under IPCC's RCP8.5 scenario from 1765 to 2265. We are going to do the continuous run from the spinup run (Section 1) so make sure that you have completed that run before you proceed.
\begin{enumerate}

\item Update source codes in your \verb|tmm| directly by doing \verb|git pull| from the remote repository.
\begin{lstlisting}[style=DOS]
 $ cd $TMMROOT
 $ git checkout TT_Release
 $ git pull origin TT_Release
\end{lstlisting}

\item Make a new run directory. Let's call it \verb|Test_co2historyRCP85| and copy all the files needed into this directory.
\begin{lstlisting}[style=DOS]
 $ cd ~/TMM2
 $ mkdir -p Runs/MOPS/TMM_co2historyRCP85
 $ cd Runs/MOPS/TMM_co2historyRCP85
 $ cp -p $TMMROOT/models/current/mops2.0/src/Makefile .
 $ cp -p -R $TMMROOT/models/current/mops2.0/matlab/* .
 $ cp -p $TMMROOT/models/current/mops2.0/runscripts/* .
\end{lstlisting}

\item Compile mops as we have done in the spinup run. Don't forget to load modules and make sure that environmental variables \verb|$TMMROOT| and \verb|$PETSC_DIR| are set up properly.
\begin{lstlisting}[style=DOS]
 $ make clean all
 $ make mops
\end{lstlisting}

\item Copy the file \verb|pickup.petsc| from the spinup run directory into the current working directory. This petsc files contains the tracer concentrations from the final year of the run and is required for the continuous run.
\begin{lstlisting}[style=DOS]
 $ cp ../Test_spinup/pickup.petsc .
\end{lstlisting}

\noin Also, copy the file \verb|pickup_runoff.bin| from the spinup run directory. This binary file contains the global sedimentation from the final year of the previous run.
\begin{lstlisting}[style=DOS]
 $ cp ../Test_spinup/pickup_runoff.bin .
\end{lstlisting}

\item Edit the input generation file (\verb|make_input_files_for_mops_model.m|). The key here is to set \\ \verb|useTimeVaryingPrescribedCO2=1| and choosing the appropriate \verb|co2Scenario|, in this case RCP85. 
\lstset{language=matlab} 
\begin{lstlisting}[frame=single,basicstyle=\scriptsize,commentstyle=\color{blue}]
 % make_input_files_for_mops_model.m
 
 % Set toplevel path to GCMs configuration
 % base_path='/data2/spk/TransportMatrixConfigs/MITgcm_2.8deg';
 % base_path='/data2/spk/TransportMatrixConfigs/MITgcm_ECCO';
 % base_path='/data2/spk/TransportMatrixConfigs/MITgcm_ECCO_v4';
 base_path='~/TMM2/MITgcm_2.8deg';
 
 addpath(genpath('~/TMM2/tmm_matlab_code'));% add tmm_matlab_code to the search path
 oceanCarbonBasePath='~/TMM2/OceanCarbon';  % add OceanCarbon to the search path
 atmosDataPath=fullfile(oceanCarbonBasePath,'AtmosphericCarbonData');
 ...
  
 READ_SWRAD=0                    % Read short-wave radiation?
 useCarbon=1                     % Use simple inorganic carbon model?
 useAtmModel=0                   % Use prognostic 1-box atmosphere?
 pCO2atm_ini=280.0               % Initial pco2? (will be ignored as useAtmModel=0)
 useTimeVaryingPrescribedCO2=1   % Use prescribed pco2 pathway?
 useVirtualFlux=1                % Use DIC and Alk to calculate E-P?
 empScaleFactor=1.0              % Scaling factor for E-P (default = 1)
 %-----------------------------------
 % Modified by Tatsuro Tanioka 200907 to allow for Atmospheric CO2 option
 % For a prescribed pCO2 run, useTimeVaryingPrescribedCO2=1 and choose a scenario
 
 % Available options: 'historical', 'RCP3PD', 'RCP45', 'RCP6' and 'RCP85'
 co2Scenario='RCP85';
 %-----------------------------------
\end{lstlisting}

\item Open Matlab and make input files:
\begin{lstlisting}[style=DOS]
 $ matlab -nodesktop
 ...
 >> make_input_files_for_mops_model
\end{lstlisting}

\item Edit \verb|runscript_msi|. Important changes are commented with blue. You can manually edit the script or copy my script from \verb|~/../tanio003/TMM2/Runs/MOPS/Test_co2historyRCP85|.
\lstset{language=sh} 
\begin{lstlisting}[frame=single,basicstyle=\scriptsize,commentstyle=\color{blue}]
  1 #!/bin/bash -l
  2 #PBS -l walltime=01:00:00,nodes=1:ppn=24,pmem=2580mb
  3 #PBS -m abe
  4 #PBS -j oe
  5 #PBS -M tatsurobkkuk@gmail.com
  6
  7 cd $PBS_O_WORKDIR
  8
  9 module load intel
 10 module load impi/intel
 11 module load cmake
 12
 13 # 360 days per year with a time step of 2 steps per day:
 14 mpiexec -np 24 -hostfile $PBS_NODEFILE ./mops \
 15   -numtracers 9 \
 16   -pickup pickup.petsc \   # read initial values from file
 17   -me Ae \
 18   -mi Ai \
 19   -t0 1765.0 -iter0 0 \   # start from year 1765
 20   -deltat_clock 0.0013888888888889 \   
 21   -max_steps 360000 \  # run for 720*500 timesteps = 500 years
 22   -write_time_steps 7200 \   # output every 720*10 timestep = 10 years
 23   -o po4out.petsc,dopout.petsc,oxyout.petsc,phyout.petsc,zooout.petsc,
 detout.petsc,no3out.petsc,dicout.petsc,alkout.petsc \
 24   -external_forcing \
 25   -use_profiles \
 26   -nzeuph 2 \
 27   -biogeochem_deltat 43200.0 -days_per_year 360.0 \
 28   -burial_sum_steps 720 \
 29   -runoff_ini_file pickup_runoff.bin \ # read global sedimentation of previous run
 30   -periodic_matrix \
 31   -pco2atm_history TpCO2.bin,pCO2atm.bin \ # read prescribed pCO2 and time
 32   -use_virtual_flux \
 33   -matrix_cycle_period 1.0 -matrix_num_per_period 12 \
 34   -periodic_biogeochem_forcing \
 35   -periodic_biogeochem_cycle_period 1.0 -periodic_biogeochem_num_per_period 12 \
 36   -num_biogeochem_steps_per_ocean_step 8 \
 37   -separate_biogeochem_time_stepping \
 38   -time_avg -avg_start_time_step 169199 -avg_time_steps 720 \ 
 # output annual avg. from year 2000 (235 years after 1765)
 39   -avg_files po4avg.petsc,dopavg.petsc,oxyavg.petsc,phyavg.petsc,zooavg.petsc,
 detavg.petsc,no3avg.petsc,dicavg.petsc,alkavg.petsc \
 40   -calc_diagnostics -diag_start_time_step 169199 -diag_time_steps 720 \ 
 # output annual mean fluxes from 2000 (235 years after 1765)
 41   -diag_files fbgc1.petsc,fbgc2.petsc,fbgc3.petsc,fbgc4.petsc,fbgc5.petsc,
 fbgc6.petsc,fbgc7.petsc \
 42   > log
\end{lstlisting}

\item Submit the job to MSI queue.
\begin{lstlisting}[style=DOS]
 $ qsub runscript_msi
\end{lstlisting}

\item Processing and outputting results. Use 5 Matlab scripts \\ (\verb|n7tracers28.m,n7tracersavg28.m,n7fluxes28.m,n7physics.m,load_pco2.m|) to create .nc files. Here, I will show you how to plot $\mathrm{CO_{2}}$ timeseries and global annual mean air-sea flux of $\mathrm{CO_{2}}$ using Ferret. The script is also at \verb|~/../tanio003/TMM2/Runs/MOPS/Test_co2historyRCP85/analyzeoutput.jnl|. 
\begin{lstlisting}[style=DOS]
 $ ferret
  	NOAA/PMEL TMAP
 	PyFerret v7.5 (optimized)
 	Linux 4.15.0-1071-azure - 03/31/20
 	16-Sep-20 14:49
 yes? use pco2.nc
 yes? use co2airseaflux.nc
 yes? set w 1;plot/d=1/hlimits=1800:2120/vlimits=200:1200/title="pCO2 RCP8.5" pco2
 yes? ppl XLAB Year
 yes? ppl YLAB pCO2 (ppm)
 yes? ppl PLOT
 yes? set w 2 ; sha/d=2/x=-180:180/lev=(-Inf)(-4,4,0.8)(Inf)/palette=cmocean_balance/
 title="Annual CO2 flux (mol C m-2 yr-1)" co2airseaflux[l=10]*2*360/1000*(-1);go fland
 yes? set w 3 ; sha/d=2/x=-180:180/lev=(-Inf)(-4,4,0.8)(Inf)/palette=cmocean_balance/
 title="Annual CO2 flux (mol C m-2 yr-1)" co2airseaflux[l=100]*2*360/1000*(-1);go fland
 yes? set w 4; plot/d=2/hlimits=2000:2100/vlimits=-7:0/
 title="Ocean-atmosphere CO2 flux (PgC yr-1)" co2airseaflux[x=@din,y=@din]*2*360/1000*12/1e15*(-1)
\end{lstlisting}
(Note: Here, I'm actually using the new version of the Ferret called PyFerret and some of the commands may not be compatible with the older version that is pre-installed at MSI. To install PyFerret in your MSI directory, visit \url{https://github.com/NOAA-PMEL/PyFerret/} and follow instructions. \emph{I highly recommend PyFerret.})

\begin{figure}[b!]   % Insert Figure 1 here
   \centering
   \includegraphics[width=10cm]{pco2RCP85.pdf}
   \caption[]{$\mathrm{CO_2}$ concentration pathway under RCP8.5 scenario \citep{Meinshausen11}.}
   \label{fig:pco2RCP85}
\end{figure}

Figure \ref{fig:pco2RCP85} (\emph{Ferret:w 1}) shows the change in $\mathrm{CO_2}$ under RCP8.5 scenario. There is a rapid increase in \CO concenctration from the late 1990s. 

Figure \ref{fig:airseamap} compares annual mean $\mathrm{CO_2}$ flux in 2010 (\emph{Ferret:w 2}) and 2100 (\emph{Ferret:w 3}). Notice that in 2010, large parts of the equatorial regions are net source of $\mathrm{CO_2}$ but in 2100, larger parts are becoming sink. Also, greater part of the Southern Ocean is also expected to absorb more  $\mathrm{CO_2}$ in 2100 compared to 2010. 

Figure \ref{fig:airseamapWoolf} is a $\mathrm{CO_2}$ flux in 2010 from a study by \cite{Woolf19} who used Surface $\mathrm{CO_2}$ atlas and wind data. If you compare with the left panel of Figure  \ref{fig:airseamap}, you can see that our MOPS model does a quite good job in reproducing the large scale pattern.

\begin{figure}[h!]   % Insert Figure 2 here
   \centering
   \begin{minipage}{0.45\columnwidth}
      \centering
      \includegraphics[width=\columnwidth]{airseaflux2010.pdf}
   \end{minipage}
   \begin{minipage}{0.45\columnwidth}
      \centering
      \includegraphics[width=\columnwidth]{airseaflux2100.pdf}
   \end{minipage}
   \caption[]{Modeled map of annual $\mathrm{CO_{2}}$ flux for 2010 (Left) and for 2100 (Right). Upward fluxes are defined as positive.}
   \label{fig:airseamap}
\end{figure}

\begin{figure}[h!]   % Insert Figure 3 here
   \centering
   \includegraphics[scale=0.1]{Woolf19_GBC_Fig1.jpg}
   \caption[]{Map of annual $\mathrm{CO_{2}}$ flux in 2010 from $\mathrm{CO_2}$ and wind data \citep{Woolf19}. Compare this with Figure \ref{fig:airseamap}.}
   \label{fig:airseamapWoolf}
\end{figure}

Figure \ref{fig:airseatimeseries} (\emph{Ferret:w 4}) is a globally integrated sea-air $\mathrm{CO_2}$ flux projections under RCP8.5 scenario.The negative value means net uptake of $\mathrm{CO_2}$ by ocean. For a comparison, we show the similar projection using the CESM and CMIP5 (Figure \ref{fig:airseatimeseries_cmip5}a-b.) from \cite{Lovenduski16}. Again, notice that MOPS's result is largely consistent in terms of the magnitude. 

\begin{figure}[H]   % Insert Figure 4 here
   \centering
   \includegraphics[scale=0.35]{airseaflux_timeseries2000to2100.pdf}
   \caption[]{Modeled annual-mean globally integrated sea-air $\mathrm{CO_2}$ flux projections under RCP8.5 scenario.}
   \label{fig:airseatimeseries}
\end{figure}

\begin{figure}[H]   % Insert Figure 5 here
   \centering
   \includegraphics[trim=0 760 0 0,clip,scale=0.3]{Lovenduski16_GBC_Fig2.jpg}
   \caption[]{Modeled annual-mean globally integrated sea-air $\mathrm{CO_2}$ flux projections \citep{Lovenduski16} with CESM (a) and CMIP5 models (b). Compare this with Figure \ref{fig:airseatimeseries}.}
   \label{fig:airseatimeseries_cmip5}
\end{figure}

\end{enumerate}


\clearpage
\bibliography{reference} 
\bibliographystyle{apalike}
\end{document}



























